# Data Preparation Pipeline Documentation

This document outlines the step-by-step process for generating the `final_local_train_dataset.json`, the final training dataset for task one. The pipeline involves several scripts that process raw data and format it into the required structure.

## 1. Initial Data Processing

The data preparation process begins with the `prepare_data_train.sh` script located in the `data_preprocess` directory. This script orchestrates the initial data processing steps by executing a series of Python scripts.

**Key Scripts:**

*   `extract_wts_frame_bbox_anno.py`: Extracts bounding box annotations for the WTS dataset.
*   `extract_bdd_frame_bbox_anno.py`: Extracts bounding box annotations for the BDD dataset.
*   `draw_bbox_on_frame.py`: Draws the extracted bounding boxes on the corresponding image frames.
*   `transform_llava_format.py`: Transforms the annotated data into a LLaVA-compatible format.

**Execution:**

```bash
cd /home/deepzoom/arv-aicity2-data/Park/AICITY2024_Track2_AliOpenTrek_CityLLaVA/data_preprocess
bash prepare_data_train.sh
```

**Generated Files:**

*   `processed_anno/frame_bbox_anno/wts_train_all_video_with_bbox_anno_first_frame.json`
*   `processed_anno/frame_bbox_anno/bdd_train_all_video_with_bbox_anno_first_frame.json`
*   Images with bounding boxes saved in `data/WTS/` and `data/BDD_PC_5k/` directories.
*   `processed_anno/llava_format/wts_bdd_train.json`

This script processes both the WTS and BDD datasets, preparing them for the final conversion step.

## 2. Final Conversion to LLaMA Factory Format

The final step in the data preparation pipeline is to convert the processed data into the exact format required by the LLaMA Factory. This is accomplished using the `prepare_final_data.py` script.

This script takes the intermediate `wts_bdd_train.json` file generated by the previous step and restructures it to be compliant with the ShareGPT multi-modal format. The output of this script is the `final_local_train_dataset.json` file.

**Key Script:**

*   `prepare_final_data.py`: Converts the processed data into the final LLaMA Factory format.

**Execution:**

```bash
python /home/deepzoom/arv-aicity2-data/Park/AICITY2024_Track2_AliOpenTrek_CityLLaVA/data_preprocess/prepare_final_data.py \
    /home/deepzoom/arv-aicity2-data/Park/AICITY2024_Track2_AliOpenTrek_CityLLaVA/data_preprocess/processed_anno/llava_format/wts_bdd_train.json \
    /home/deepzoom/arv-aicity2-data/Park/AICITY2024_Track2_AliOpenTrek_CityLLaVA/data_preprocess/processed_anno/llava_format/final_local_train_dataset.json
```

**Generated File:**

*   `/home/deepzoom/arv-aicity2-data/Park/AICITY2024_Track2_AliOpenTrek_CityLLaVA/data_preprocess/processed_anno/llava_format/final_local_train_dataset.json`

By following these two steps, the raw data is transformed into the final `final_local_train_dataset.json` file, which is then used to train the model.